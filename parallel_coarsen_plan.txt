step 1: user marks collapse codes on all edges, expected to be synchronized
step 2: quicly check for all codes being DONT_COLLAPSE, exit early
step 3: check classification on edge closures, unmark as necessary
        this requires col_codes to be synchronized, but doesn't need ghosting
        do another quick check for nothing to do.
step 4: check the qualities of proposed edge collapses...
        checking a single collapse requires the vertex to be local.
        checking "an edge" requires both vertices be local.
        ... is it true that an owned edge has both vertices on
            the partition interior ? I think so....
        assuming that, no worries ?
        run the collapse quality check code, then synchronize the two outputs:
        edge collapse codes, and edge collapse qualities (two doubles per edge).
        do another quick check for nothing to do.
step 5: now we have a ghosted mesh with all collapses that pass classification
        and quality requirements attached to the edges as collapse codes
        and collapse qualities.
        now, each vertex will choose the highest quality collapse affecting it.
        this requires synchronizing the vertex candidate and quality arrays afterwards.
step 6: then we go into the independent set system, which gives a subset of
        the candidates.
        finally we can give this independent set to the unghosting system
        to arrive at the serial-similar mesh to use from now on.
step 7: there are now vertex candidates and qualities, as well as edge
        collapse codes and qualities, all tagged.
        we recover the "destination vertex" by having each vertex look
        around its edges and choose a collapse with equal quality to the
        one it has. we don't care much about ties at this point, since
        quality is the only metric of goodness.
        from here on out we should be able to reuse the existing system for
        serial coarsening.
